{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjarkedc/RAG_FLAN_T5/blob/main/t5_flan_rag_finetuned_no_output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DoNopsBYygiD"
      },
      "id": "DoNopsBYygiD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank-bm25 nltk transformers sentencepiece"
      ],
      "metadata": {
        "id": "c5beGR5iU8Ve"
      },
      "id": "c5beGR5iU8Ve",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, T5TokenizerFast\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "lm = \"drive/MyDrive/data-anlp/flant5-base-starwars/\" # change to appropriate drive\n",
        "finetuned_model = T5ForConditionalGeneration.from_pretrained(lm)\n",
        "tokenizer_fine_tuned = T5TokenizerFast.from_pretrained(lm)"
      ],
      "metadata": {
        "id": "Srt9sdLntxUL"
      },
      "id": "Srt9sdLntxUL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_docs(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        file_content = file.read()\n",
        "\n",
        "    # Regular expression to match <doc> elements\n",
        "    doc_pattern = re.compile(r'<doc id=\"([^\"]+)\" url=\"([^\"]+)\" title=\"([^\"]+)\">(.*?)</doc>', re.DOTALL)\n",
        "\n",
        "    # Find all matches\n",
        "    matches = doc_pattern.findall(file_content)\n",
        "\n",
        "    # Extract data and create a list of dictionaries\n",
        "    docs = [{'id': match[0], 'url': match[1], 'title': match[2], 'text': match[3].strip()} for match in matches]\n",
        "    return docs\n",
        "\n",
        "# Create a DataFrame\n",
        "def create_dataframe(docs):\n",
        "    return pd.DataFrame(docs)\n",
        "\n",
        "# Preprocess text: tokenize and remove stopwords - preprocess is the problem\n",
        "def preprocess(text):\n",
        "    # Define a set of special characters\n",
        "    special_chars = set(string.punctuation)\n",
        "\n",
        "    # Initialize the stemmer\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    # Load set of English stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Tokenize and convert to lowercase\n",
        "    tokens = word_tokenize(text.lower())\n",
        "\n",
        "    # Preprocess tokens\n",
        "    processed_tokens = []\n",
        "    for token in tokens:\n",
        "        if token not in stop_words and not all(char in special_chars for char in token):\n",
        "            stemmed_token = stemmer.stem(token)\n",
        "            processed_tokens.append(stemmed_token)\n",
        "\n",
        "    return processed_tokens\n"
      ],
      "metadata": {
        "id": "hIxN0Ny80dv6"
      },
      "id": "hIxN0Ny80dv6",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = 'drive/MyDrive/data-anlp/starwarsfandomcom-removed-space-and.txt'  # Replace with the actual path to your file\n",
        "docs = parse_docs(file_path)\n",
        "df = create_dataframe(docs)\n",
        "df['tokenized_text'] = df['text'].apply(preprocess)\n",
        "df = df[df['title'] != df['text']]"
      ],
      "metadata": {
        "id": "E4_fyi09_8Zf"
      },
      "id": "E4_fyi09_8Zf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_bm25(query, num_results=50):\n",
        "    query_tokens = preprocess(query)\n",
        "    print(query_tokens)\n",
        "    doc_scores = bm25.get_scores(query_tokens)\n",
        "    top_doc_indices = sorted(range(len(doc_scores)), key=lambda i: doc_scores[i], reverse=True)[:num_results]\n",
        "    return df.iloc[top_doc_indices]['text'].str.cat(sep=' ')\n",
        "\n",
        "def generate_response(query, context):\n",
        "    # Concatenate the query and context\n",
        "    input_text = f'Answer this question: \"{query}\". Based off the following context: \"{context}\".'\n",
        "\n",
        "    # Tokenize the input text\n",
        "    input_ids = tokenizer_fine_tuned.encode(input_text, return_tensors='pt')\n",
        "\n",
        "    # Truncate the input to the model's max length if necessary\n",
        "    max_length = tokenizer_fine_tuned.model_max_length\n",
        "    if input_ids.size(1) > max_length:\n",
        "        input_ids = input_ids[:, :max_length]\n",
        "\n",
        "    truncated_input_text = tokenizer_fine_tuned.decode(input_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    output_ids = finetuned_model.generate(input_ids)[0]\n",
        "\n",
        "    response = tokenizer_fine_tuned.decode(output_ids, skip_special_tokens=True)\n",
        "\n",
        "    return response, context, truncated_input_text\n"
      ],
      "metadata": {
        "id": "J8QvNaZgYYK_"
      },
      "id": "J8QvNaZgYYK_",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_set_path = '/content/drive/MyDrive/data-anlp/star_wars_dataset_dev/' # add appropriate path with datasets\n",
        "test_set_path = '/content/drive/MyDrive/data-anlp/star_wars_dataset_test/' # add appropriate path with datasets\n",
        "\n",
        "# Function to read a file and return a list of lines\n",
        "def read_file_to_list(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return [line.strip() for line in file]\n",
        "\n",
        "def robs_eval(gold, pred):\n",
        "    \"\"\"\n",
        "    An answer is considered correct if at least half of the gold\n",
        "    tokens are in the prediction. Note that this is a shortcut,\n",
        "    and will favor long answers.\n",
        "    \"\"\"\n",
        "    gold = set(gold.strip().lower().replace('.', '').split(' '))\n",
        "    pred = set(pred.strip().lower().replace('.', '').split(' '))\n",
        "    return len(gold.intersection(pred)) >= len(gold)/2\n",
        "\n",
        "\n",
        "# Load the data\n",
        "dev_questions = read_file_to_list(text_set_path + 'questions.txt')\n",
        "dev_answers = read_file_to_list(text_set_path + 'answers.txt')\n",
        "\n",
        "test_questions = read_file_to_list(test_set_path + 'questions.txt')\n",
        "test_answers = read_file_to_list(test_set_path + 'answers.txt')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "juVCtGgclAJQ"
      },
      "id": "juVCtGgclAJQ",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### grid search\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "max_pairs = len(dev_questions)\n",
        "\n",
        "param_grid = {\n",
        "    'k1': np.linspace(0.75, 1.75, num=3),\n",
        "    'b': np.linspace(0.3, 0.7, num=3)\n",
        "}\n",
        "grid = ParameterGrid(param_grid)\n",
        "tokenized_corpus = df['tokenized_text'].tolist()\n",
        "best_score = -1\n",
        "best_params = None\n",
        "results = {}  # Dictionary to store results\n",
        "\n",
        "for params in tqdm(grid, desc=\"Grid Search\"):\n",
        "    print(f\"\\n{params}\")\n",
        "    bm25 = BM25Okapi(corpus=tokenized_corpus, k1=params['k1'], b=params['b'])\n",
        "    total_correct = 0\n",
        "\n",
        "    for query, answer in tqdm(zip(dev_questions[:max_pairs], dev_answers[:max_pairs]), total=len(dev_questions[:max_pairs]), desc=\"Evaluating Queries\"):\n",
        "        context = query_bm25(query, 15)\n",
        "        response, context, truncated_input_text = generate_response(query, context)\n",
        "        print(f\"\"\"\n",
        "{query}\n",
        "{response}\n",
        "{answer}\n",
        "----------------------------------------------\"\"\")\n",
        "\n",
        "        if robs_eval(answer, response):\n",
        "            total_correct += 1\n",
        "            print(\"total = \" + str(total_correct))\n",
        "\n",
        "    # Save the results\n",
        "    results[str(params)] = total_correct\n",
        "\n",
        "    # Assess the effectiveness of the parameters\n",
        "    print(f\"Total Correct: {total_correct}\")\n",
        "    if total_correct > best_score:\n",
        "        best_score = total_correct\n",
        "        best_params = params\n",
        "\n",
        "print(f\"Best Params: {best_params}, Best Score: {best_score}\")\n",
        "# Print the results dictionary\n",
        "print(\"\\nAll Results:\")\n",
        "for param, score in results.items():\n",
        "    print(f\"{param}: {score}\")"
      ],
      "metadata": {
        "id": "yXH3nvrxjMZQ"
      },
      "id": "yXH3nvrxjMZQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set_path = '/content/drive/MyDrive/data-anlp/star_wars_dataset_test/'\n",
        "test_questions = read_file_to_list(test_set_path + 'questions.txt')\n",
        "test_answers = read_file_to_list(test_set_path + 'answers.txt')\n",
        "\n",
        "bm25 = BM25Okapi(corpus=df['tokenized_text'].tolist(), k1=1.75, b=0.3)\n",
        "\n",
        "data = []\n",
        "total_correct = 0\n",
        "\n",
        "for query, answer in tqdm(zip(test_questions, test_answers), total=len(test_answers), desc=\"Processing\"):\n",
        "    context = query_bm25(query, 15)\n",
        "\n",
        "    response, context, truncated_input_text = generate_response(query, context)\n",
        "\n",
        "    # Print the text (optional, can be removed if not needed)\n",
        "    print(f\"\"\"\n",
        "{truncated_input_text}\n",
        "{response}\n",
        "{answer}\n",
        "----------------------------------------------\"\"\")\n",
        "\n",
        "    # Check if the response is correct\n",
        "    if robs_eval(answer, response):\n",
        "        total_correct += 1\n",
        "        print(\"total = \" + str(total_correct))\n",
        "\n",
        "    data.append({'Query': query, 'Correct Answer': answer, 'Model Response': response})\n",
        "\n",
        "df_results = pd.DataFrame(data)\n",
        "print(f\"Total correct answers: {total_correct}/{len(test_answers)}\")\n"
      ],
      "metadata": {
        "id": "iOXrsnJDbYKS"
      },
      "id": "iOXrsnJDbYKS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make context list and then generate test-based on that"
      ],
      "metadata": {
        "id": "fSGa3srSwyMS"
      },
      "id": "fSGa3srSwyMS"
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/data-anlp/contextfile.txt'\n",
        "list_from_file = []\n",
        "with open(file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        list_from_file.append(line.strip())"
      ],
      "metadata": {
        "id": "HZ7Tdyeywxxy"
      },
      "id": "HZ7Tdyeywxxy",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from transformers import set_seed\n",
        "test_set_path = '/content/drive/MyDrive/data-anlp/star_wars_dataset_test/'\n",
        "test_questions = read_file_to_list(test_set_path + 'questions.txt')\n",
        "test_answers = read_file_to_list(test_set_path + 'answers.txt')\n",
        "\n",
        "data = []\n",
        "total_correct = 0\n",
        "\n",
        "# Change generator in order to make sure the context is the same\n",
        "def generate_response_context(context):\n",
        "    # Concatenate the query and context\n",
        "    input_text = context\n",
        "\n",
        "    # Tokenize the input text\n",
        "    input_ids = tokenizer_fine_tuned.encode(input_text, return_tensors='pt')\n",
        "\n",
        "    # Truncate the input to the model's max length if necessary\n",
        "    max_length = tokenizer_fine_tuned.model_max_length\n",
        "    if input_ids.size(1) > max_length:\n",
        "        input_ids = input_ids[:, :max_length]\n",
        "\n",
        "    truncated_input_text = tokenizer_fine_tuned.decode(input_ids[0], skip_special_tokens=True)\n",
        "    output_ids = finetuned_model.generate(input_ids)[0]\n",
        "    response = tokenizer_fine_tuned.decode(output_ids, skip_special_tokens=True)\n",
        "\n",
        "    return response, context, truncated_input_text\n",
        "\n",
        "for query, answer, context in tqdm(zip(test_questions, test_answers, list_from_file), total=len(test_answers), desc=\"Processing\"):\n",
        "\n",
        "\n",
        "    response, context, truncated_input_text = generate_response_context(context)\n",
        "\n",
        "    # Print the text (optional, can be removed if not needed)\n",
        "    print(f\"\"\"\n",
        "{truncated_input_text}\n",
        "{response}\n",
        "{answer}\n",
        "----------------------------------------------\"\"\")\n",
        "\n",
        "    # Check if the response is correct\n",
        "    if robs_eval(answer, response):\n",
        "        total_correct += 1\n",
        "        print(\"total = \" + str(total_correct))\n",
        "\n",
        "    data.append({'Query': query, 'Context': truncated_input_text , 'Correct Answer': answer, 'Model Response': response})\n",
        "\n",
        "df_results = pd.DataFrame(data)\n",
        "print(f\"Total correct answers: {total_correct}/{len(test_answers)}\")"
      ],
      "metadata": {
        "id": "CHpMEs50x22o"
      },
      "id": "CHpMEs50x22o",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "poetry-venv",
      "language": "python",
      "name": "poetry-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}